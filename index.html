<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ji Sue Lee</title>

    <meta name="author" content="Ji Sue Lee">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ji Sue Lee
                </p>
                <p>I'm a candidate Ph.D at <a href="https://www.hanyang.ac.kr/web/eng">University of Hanyang</a> in South Korea and studying <a href="https://ebe.hanyang.ac.kr/">Electrical Engineering</a>.
                </p>
                <p>
                  I'm passionate about exploration and exploitation challenges in Reinforcement Learning (RL), Meta-RL, and Causal-RL. I'm currently researching how to optimize Meta-RL with Causal Representation Learning in mobile robot scenarios.
                </p>
                <p style="text-align:center">
                  <a href="mailto:leejisue@hanyang.ac.kr">Email</a> &nbsp;/&nbsp;
<!--                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;-->
<!--                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;-->
                  <a href="https://scholar.google.com/citations?user=-hWYMOEAAAAJ&hl=ko&authuser=2">Scholar</a> /
                  <a href="https://twitter.com/brunoleej">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/leejisue/">Github</a> /
                  <a href="https://www.linkedin.com/in/bruno-lee-7a60d242b5/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/ljs_id_photo.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 5px;" alt="profile photo" src="images/ljs_id_photo.jpeg" class="profile-img"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="recon_stop()" onmouseover="recon_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src="projects/c2a/img/motivation.png" alt="C2A preview" class="paper-primary-image" style="width:100%; height:auto;">
                    <img id="recon_image" src="projects/c2a/img/motivation.png" alt="C2A detail" class="paper-hover-image" style="width:100%; height:auto;">
                </div>
                <script type="text/javascript">
                    function recon_start() {
                        document.getElementById('recon_image').style.opacity = "1";
                    }
                    function recon_stop() {
                        document.getElementById('recon_image').style.opacity = "0";
                    }
                    recon_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/10947036">
                  <span class="papertitle">C2A: Causality-aware Context Adaptation</span>
                </a>
                <br>
                <strong>Jisu Lee</strong>, Myoung Hoon Lee and Jun Moon
                <br>
                <em>IEEE Robotics and Automation Letters (RA-L)</em>, submitted, 2025
                <br>
                <a href="https://leejisue.github.io/projects/c2a/">project page</a>    /
                <!-- <a href="data/gome_ngu.bib">bibtex</a> -->
                <br>
                <p>In this paper, we propose Causality-aware Context Adaptation (C2A), a meta-reinforcement learning framework that integrates temporal causal discovery with causal representation learning to enable sample-efficient and robust task adaptation in high-dimensional and causally sparse environments.</p>
                <!-- <p>This paper is scheduled to be submitted to IEEE Access.</p> -->
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src="https://github.com/jonbarron/website/assets/160090783/b1c7eb24-6c12-426f-9b01-02733b48ffd7" alt="GOME-NGU preview" class="paper-primary-image" style="width:100%; height:auto;">
                    <img id="recon_image" src="https://github.com/jonbarron/website/assets/160090783/b1c7eb24-6c12-426f-9b01-02733b48ffd7" alt="GOME-NGU detail" class="paper-hover-image" style="width:100%; height:auto;">
                </div>
                <script type="text/javascript">
                    function recon_start() {
                        document.getElementById('recon_image').style.opacity = "1";
                    }
                    function recon_stop() {
                        document.getElementById('recon_image').style.opacity = "0";
                    }
                    recon_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/10947036">
                  <span class="papertitle">GOME-NGU: visual navigation under sparse rewrd via Goal-Oriented Memory Encoder with Never Give Up</span>
                </a>
                <br>
                <strong>Jisu Lee</strong>, Jun Moon
                <br>
                <em>IEEE Access</em>, 2025
                <br>
                <a href="https://leejisue.github.io/projects/gome-ngu/">project page</a>    /
                <a href="https://youtu.be/jLMrcgprdCg?feature=shared">video</a> /
                <a href="data/gome_ngu.bib">bibtex</a>
                <br>
                <p>In this paper, we propose the Goal-Oriented Memory Encoder (GOME) with Never Give Up (NGU) algorithm to enhance visual navigation in sparse reward environments.</p>
                <!-- <p>This paper is scheduled to be submitted to IEEE Access.</p> -->
              </td>
          </tbody></table>

          <hr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>

          <table border=0 class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='https://leejisue.github.io/theory/rl-basics/img/logo.jpg' width="100%" style="max-height: 160px; object-fit: contain;">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <a href="https://leejisue.github.io/theory/rl-basics"><papertitle><big>Reinforcement Learning Basics with JAX</papertitle></big></a> (March. 2025 - TBD)
                  <br>
                  This project serves as a comprehensive guide for learning and implementing reinforcement learning (RL) algorithms using JAX. It is designed for both researchers and practitioners, providing structured tutorials and hands-on code implementations.
                  <ul style="padding-left: 20px;">
                    <li style="padding-bottom: 5px;">
                      Covers fundamental RL topics such as Markov Decision Processes and Q-learning.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Explores advanced methods, including policy gradient techniques and model-based RL.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Provides a structured 15-week curriculum with practical exercises and real-world applications.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Includes video tutorials and hands-on projects to reinforce learning.
                    </li>
                  </ul>
              </td>
          </tr>
          </tbody></table>

          <table border=0 class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='https://github.com/user-attachments/assets/59eb2df3-bbbf-4027-aeb0-15ec7ba616ac' width="100%" style="max-height: 160px; object-fit: cover;">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <a href="https://paper-reviews97.github.io/"><papertitle><big>Paper Reviews</papertitle></big></a> (April. 2025 - TBD)
                  <br>
                  Paper Reviews is a curated platform offering in-depth reviews of cutting-edge research in AI, Machine Learning, and Robotics. Designed for both researchers and practitioners, it provides comprehensive insights, accessible explanations, and regular updates on influential publications.
                  <ul style="padding-left: 20px;">
                    <li style="padding-bottom: 5px;">
                      Curated collection of influential research papers across diverse AI domains.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Detailed reviews and technical analyses that simplify complex concepts.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Regular updates featuring featured papers and new research developments.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Community-driven content tailored for both experts and newcomers.
                    </li>
                  </ul>
              </td>
          </tr>
          </tbody></table>

        <hr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Projects</h2>
              </td>
            </tr>
        </tbody></table>

        <!-- Projects 항목에 호버 효과 적용 -->
        <table border=0 class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:20px;"><tbody>
            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='https://github.com/jonbarron/website/assets/160090783/b720ce58-f2b5-4a40-91a6-e368bf741427' width="100%" style="max-height: 160px; object-fit: contain;">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <a href="https://mobilesimulator.github.io/MobileSimulator/"><papertitle><big>NVIDIA Isaac-Sim Mobile Robot Simulator</papertitle></big></a> (May. 2024 - TBD)
                  <br>
                  We are proceeding with the NVIDIA Isaac-Sim Mobile Robot (Franka Research 3, Husky, QCar, Husky + Franka Research 3) unified platform to ease usage for beginner to master courses.
                  <ul style="padding-left: 20px;">
                    <li style="padding-bottom: 5px;">
                      We are developing a new user interface (UI) in the NVIDIA Isaac-Sim.
                    </li>

                    <li style="padding-bottom: 5px;">
                      In our implemented UI, we demonstrated several mobile robots and environments.
                    </li>

                    <li style="padding-bottom: 5px;">
                      We demostrated a human simulator and sensor applications (stereo camera, LiDAR).
                    </li>

                    <li style="padding-bottom: 5px;">
                      We demonstated simple ablation scenarios (SLAM, path-planning) for mobile robots.
                    </li>
                  </ul>
              </td>
          </tr>          
        </tbody></table>

        <table border=0 class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:20px;"><tbody>
          <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='images/pj_semantic_seg.png' width="100%" style="max-height: 160px; object-fit: contain;">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <a href="https://leejisue.github.io/portfolio/carla-semantic-segmentation-challenge"><papertitle><big>CARLA Semantic Segmentation Challenge</papertitle></big></a> (May. 2023 - May. 2023)
                  <br>
                  Creating a semantic segmentation model for autonomous driving in the <a href="https://carla.org//">CARLA</a> environment using a pre-trained model.
                  <ul style="padding-left: 20px;">
                    <li style="padding-bottom: 5px;">
                      Achieved real-time segmentation under diverse weather conditions.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Utilized pre-trained DeepLabv3 models and fine-tuned architectures (U-Net, Mask-RCNN).
                    </li>

                    <li style="padding-bottom: 5px;">
                      Optimized class definitions by remapping 28 classes into 12 key categories.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Enhanced scene understanding for autonomous driving applications.
                    </li>
                  </ul>
              </td>
          </tr>
        </tbody></table>

        <table border=0 class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='https://github.com/jonbarron/website/assets/160090783/15392c13-cbe8-4210-a9e1-d408144b0f87' width="100%" style="max-height: 160px; object-fit: contain;">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <!-- <a href="https://leejisue.github.io/portfolio/hyperdrive"><papertitle><big>HyperDrive: Advanced Reinforcement Learning for Autonomous Racing</papertitle></big></a> (TBD) -->
                  <papertitle><big>HyperDrive: Advanced Reinforcement Learning for Autonomous Racing</papertitle></big></a> (TBD)
                  <br>
                  A research-driven project exploring advanced reinforcement learning techniques for autonomous racing, conducted using the Learn to Race simulation platform.
                  <ul style="padding-left: 20px;">
                    <li style="padding-bottom: 5px;">
                      Developed and evaluated various reinforcement learning algorithms, including Online RL, Offline RL, Transformer-based RL, State Space Models, and Meta-RL.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Designed a benchmarking framework to compare algorithm performance in terms of speed, generalization, and sample efficiency across multiple racing tracks.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Implemented policy optimization techniques to enhance driving stability and reduce lap times in high-speed racing scenarios.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Conducted extensive experiments using large-scale GPU clusters, optimizing computational efficiency for real-time decision-making in autonomous driving.
                    </li>
                  </ul>
              </td>
          </tr>
        </tbody></table>

        <table border=0 class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:20px;"><tbody>
          <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='https://i.imgur.com/eE4QxhC.png' width="100%" style="max-height: 160px; object-fit: contain;">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <a href="https://position-drone.github.io/"><papertitle><big>Drone Position Control using Reinforcement Learning</papertitle></big></a> (Aug. 2025 - Sep. 2025)
                  <br>
                  A collaborative research project with KAUST laboratory focusing on autonomous drone control using reinforcement learning techniques for precise position control.
                  <ul style="padding-left: 20px;">
                    <li style="padding-bottom: 5px;">
                      Developed and implemented RL-based position control algorithms for quadrotor drones in complex 3D environments.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Collaborated with KAUST research team to design reward functions optimized for stability and trajectory tracking accuracy.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Conducted extensive simulations comparing traditional PID controllers with learned policies, achieving superior performance in dynamic scenarios.
                    </li>

                    <li style="padding-bottom: 5px;">
                      Integrated state-of-the-art deep RL algorithms (PPO, SAC) for real-time adaptation to environmental disturbances and uncertainties.
                    </li>
                  </ul>
              </td>
          </tr>
        </tbody></table>

        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <p>Updated March 2025.</p>
                <p style="text-align:right;font-size:small;">
                  The source code of this website is owned by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>